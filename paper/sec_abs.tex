%!TEX root = main.tex

In recent years, multi-task learning (MTL) has proved to be a powerful learning framework that promotes performance in supervised learning problems by transferring knowledge among multiple tasks. Distributed MTL is one prevalent setting where the data is separated across different locations. The issue of privacy arises when distributed MTL is applied on the geographically separated data. These datasets contains personal information such as financial and medical records, which is very sensitive and should be away from exposure. Considering the proliferation of various private data, privacy-preserving distributed MTL frameworks are in great need. On the other hand, differential privacy (DP) is one of the most important privacy concepts that are suitable for this genre of frameworks. In this report, we put up with a novel idea: \textbf{A}synchronous \textbf{I}nteractive \textbf{D}istributed \textbf{P}rivate \textbf{M}ultitask \textbf{L}earning \textbf{F}ramework with Trustworthy Data Aggregator (AIDPMTLF) to address the privacy issue under distributed MTL setting. The proposed framework adds carefully designed perturbation on the data aggregator. We also provide theoretical guarantees of the proposed framework and extensive empirical results to illustrate our idea. 